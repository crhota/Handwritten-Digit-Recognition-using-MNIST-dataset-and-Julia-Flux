{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition using MNIST dataset and Julia Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 1.00\n",
    "\n",
    "- Version 1.00: Initial Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the \"**Deep Learning with Flux**\" course provided by **Julia Academy** (https://juliaacademy.com/courses/). I express my sincere gratitude to **Dr. Matt Bauman** for presenting this course and sharing the associated Jupyter Notebook. This notebook is associated with fourth lecture \"**Recognizing handwriting with a neural network**\" of the mentioned course.\n",
    "\n",
    "As I was attending the lecture, I realized I need to code myself to understand and record my inferences and in the process came up with this working notebook. Intent here is to have this for my future reference as well as be useful to someone new to the field learning ML/DL.\n",
    "\n",
    "This notebook implements a **neural network** using **Julia Flux** to **recognize handwritten digits** from **MNIST dataset**. \n",
    "\n",
    "Details of what this notebook covers is listed below:\n",
    "- How to setup the Environment\n",
    "- Where to get the datasets from \n",
    "- Which packages to install and how\n",
    "- Understanding MNIST dataset\n",
    "- Prepare input data\n",
    "- Create output labels\n",
    "- Use batch to improve efficiency and create training batch\n",
    "- Define the model\n",
    "- Train the model few times and observe improving loss value\n",
    "- Show Loss automatically using callback\n",
    "- Evaluate accuracy of prediction\n",
    "- Update Model and improve accuracy\n",
    "\n",
    "**Initial Model**\n",
    "- **784 Inputs** -> **10 Outputs** with **Identity** Activation Function -> **Softmax**\n",
    "- Loss Function = **Crossentropy**\n",
    "- Optimizer Function = **ADAM**\n",
    "- **Train** Accuracy = **96.36%**\n",
    "- **Test** Accuracy = **89.88%**\n",
    "- Total **Number of Parameters** of the Model = **7850**\n",
    "<img src = \"images/InitialModelTrainTest1.JPG\">\n",
    "\n",
    "**Updated Model**\n",
    "- **784 Inputs** -> **20 hidden neurons** with **relu** as Activation Function) -> **10 Outputs** with **Identity** Activation Function -> **Softmax**\n",
    "- Loss Function = **Crossentropy**\n",
    "- Optimizer Function = **ADAM**\n",
    "- **Train** Accuracy = **99.84%**\n",
    "- **Test** Accuracy = **90.72%**\n",
    "- Total **Number of Parameters** of the Model = **15910**\n",
    "<img src = \"images/UpdatedModelTrainTest1.JPG\">\n",
    "\n",
    "**Summary**\n",
    "1. You can notice that the test loss is increasing after we added more complexity (more parameters) to the model i.e. it is overfitting => We need to **reduce the number of parameters or train with more samples**.\n",
    "2. Our input is a 28x28 image, however, we are feeding it to the model as a vector which loses the spatial information of the one pixel to the other. And we did so because the the model topology (multi-layer perceptron) expects the input in a vetor form. Also we used the Dense function which connects every input to every output as needed for a multi-layer perceptron which probably could be adding more complexity than needed. We can alternatively go for a **model topology which retains the image structure** as a matrix for processing and connects few inputs to few outputs i.e. a Convolution Neural Network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to setup the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using **Julia REPL** and **Jupyter Environment** for the notebook. If you wish to setup this environment, here is what I did:\n",
    "- I installed Julia 1.3.1 from: https://julialang.org/downloads/\n",
    "- Once I installed Julia, I invoked Jupyter Environment from the REPL using following:\n",
    "    - julia> using IJulia\n",
    "    - julia> notebook(detached=true)     \n",
    "- I created a New Notebook (File->New Notebook... select Julia) ... which is this notebook and started editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to get the datasets from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using MNIST dataset which comes along with Julia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which packages to install and how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the packages I did not have on my system - so that can use them during the course - by using following code at the REPL\n",
    "- **Flux**\n",
    "    - is the deep learning package from Julia - helps create/train/use models\n",
    "    - julia> using Pkg\n",
    "    - julia> Pkg.add(\"Flux\")\n",
    "- **Plots**\n",
    "    - helps create graphs for visualization as you build & refine your model\n",
    "    - julia> using Pkg\n",
    "    - julia> Pkg.add(\"Plots\")\n",
    "- **Images**\n",
    "    - helps work with images\n",
    "    - julia> using Pkg\n",
    "    - julia> Pkg.add(\"Images\")\n",
    "- **Printf**\n",
    "    - helps print data onto the terminal\n",
    "    - julia> using Pkg\n",
    "    - julia> Pkg.add(\"Printf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **60000** **grey scale** images of handwritten digits, with **784 pixels** stored as **28x28 matrices** and **60000 labels** defining the corresponding digits having values in the range of **0 to 9**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: CuArrays.jl only supports CUDNN v7.6 or higher\n",
      "└ @ CuArrays C:\\Users\\Chinmoy\\.julia\\packages\\CuArrays\\HE8G6\\src\\CuArrays.jl:121\n"
     ]
    }
   ],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Data.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = MNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST.labels();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Array{Gray{Normed{UInt8,8}},2},1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Gray{Normed{UInt8,8}},2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: 2 denotes the image is a matrix\n",
    "typeof(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Int64,1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIKSURBVGje7dpPiI1RGMfxzyAL8qfZmFISi1EiFigpSZJiMbGhbLBDVjZ2FqSwQBazUhayxYryd6FuTf5syN6fHYM0yGDxvJPr3tu9c2eKc0/nW29v5z3ve3/93qdz3uc551IoFAqFQqHQ+/R1+8BMLKhrH8EcDOIwzmEvvuIMTjY8P+NfO8xfcFanG5ZgNjZiExZid4v7XuMihvAZz/EwBYf5C7Ydh2tx19/jrhU/cQBfqvZbfMCrFBzmL9g2hv2oYVmLvhpGsQXfdY7zf3OYv2DbufQ9jmMnnoq5Ep5hmxh3K3EsZYf5C04qp5kvvnHDOIj9uNYrDvMX7JjTwKfq/LE6H8J18R1M3mH+gl3VFnNxC5uxA3d6wWH+gl3Xh8vxROQz9zGCy/iVqsP8BbuOIVEDXsG8qn0CV/EuRYf5C04phrAK57G1ag/jFN6k5jB/wSnHkFiz2SXGZB/uiZojKYf5C04rhhN8EwnuD2zHg5Qc5i84qdqiFauxB+vqfuQFHqXmMH/BrmM4iKMirxmouz4ucppONWP+rzTduXQA+8T+0tKGvhGRz9xM0WH+gh1juEisiV7Cioa+Gs7ihsmv2eT/StOJYb+oF9Zo3rd4LOqK2xhL3WH+gk0x3CD2KtZjcUPfGC7gtD97hck7zF+wKacZqo4JXoo10nHxP4vRXnOYv2ChUCgUps9vDE1MYMzifHwAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIISURBVGje7dlPiE1RHAfwD02jRmwMGmUhYkUWFixYjBBNlB2RoilGsqHEjiYLC1Y22GiKhSXJRqbssJGwsCISSf5GSRa/K8/ozdw3U+69p/PdvPPOPd3v+/bt+87vdw4ZGRkZGRkZGRkZ1WPaVF+wFD3F+BXeTLB++v9WmD7hpDxch8UYxHLMLOYfYxNe1klh+oQde7geB7C9+P4C34vxHOHnSjzFXJzFfGyoSmH6hF2dLN6BkyKD+/Ac9/CxeL4LZ4S/l3Adi7CtSoXpE5bOYR/uFJ9DuIofY9Z0idwN4RO+4QhGqlSYPmHpHA6I+mW3vz1pxSAOFuNR7MSXqhWmT1jaw37hx4Mx8zPEXncCy/ABh3ENX+ugMH3C0h72YRhPWn7pWhzFFrzFObFf1kph+oSl98Pb6BZ+fcYeUbf8xHlcxv06KkyfsHQO7wrf1uAQVuEmThfPaqswfcKOeouFwrfX2IiHTVCYPuGE/6Xd4uzlijhTG8Fe//YVtVWYPuGEOdwvapVnWCKyN1n/KlGYPuG4Hp4SPcNFUW/eEmczjVKYPmFbD/uxFRdwvJjrFXcTjVKYPmFbDwfEncQjvMNsvBfnMJ3UoZUrTJ+wrYe/e72eloWzcKNpCtMnbFuXLhB3Er2in1iBeVgtstkYhekTjttbbMYxkcFRf/bFRilMnzAjIyMjY+r4BXa7TEmk5aIOAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the numeric content of the images using Float64 as broadcast on each image matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.498039  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.25098   0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " ⋮                             ⋮         ⋱                 ⋮            \n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.215686  0.67451      0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.533333  0.992157     0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Float64.(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the images are of same size (784 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives unique elements in the array\n",
    "unique([1,2,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives we have 60000 images\n",
    "length(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length when broadcasted on each of the 60000 images, gives a 60000 array... each element corresponding to the length of \n",
    "# the corresponding image\n",
    "length.(images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using unique on top of above gives the unique values of length seen\n",
    "# what is the siginificance of using []... if you do not use, the result is an 1-element array instead of a number.\n",
    "n_inputs = unique(length.(images))[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the labels have values in the range of 0 to 9 i.e. total unique values = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       " 5\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 9\n",
       " 2\n",
       " 3\n",
       " 6\n",
       " 7\n",
       " 8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_outputs = length(unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our neural network (here a multi-layer perceptron) accepts a vector. Our images are in the matrix form (28x28). Also the values of the images are in grey scale. We need to have them in numeric form (Float64) for the neural network to work effectively on it. We will define a custom function that will do the job for us.\n",
    "- We will convert few of the images of the total 60000, which will be used for model training. This helps keep the rest images unseen by the model and hence can be used for validation to see how good the model is doing for an unknown input. \n",
    "- Each input data will be **784 element vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮  \n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float64 broadcast converts each grey scale pixel value to Float64\n",
    "# vec function converts the matrix form of the data to vector form\n",
    "vec(Float64.(images[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(img) = vec(Float64.(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000-element Array{Array{Float64,1},1}:\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " ⋮                                                                                                      \n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcast preprocess to convert each image in the images[1:5000]\n",
    "xs = preprocess.(images[1:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(xs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one hot encoding to generate the output labels as each of them will correspond to a probabaility of they corresponding to a digit value between 0 to 9. Each output label will be as **10 element vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000-element Array{Flux.OneHotVector,1}:\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " ⋮                             \n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = [Flux.onehot(labels, 0:9) for labels in labels[1:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(ys[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use batch to improve efficiency and create training batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember batch converts the data to matrices form which is very suitable for operations on GPU and hence are faster in execution => improves efficiency. We will define a custom function to create a batch for a given range and use it create training batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Input Data**: Batch converts the 5000 number of 784 element vectors to **784x5000 matrix** : each column corresponds to an instance\n",
    "- **Output Labels**: Batch converts the 5000 number of 10 element labels to **10x5000 matrix** : each column corresponds to an instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_batch(r)\n",
    "    xs = [preprocess(img) for img in images[r]]\n",
    "    ys = [Flux.onehot(labels, 0:9) for labels in labels[r]]\n",
    "    return (Flux.batch(xs), Flux.batch(ys))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbatch = create_batch(1:5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(trainbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×5000 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                      \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbatch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×5000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  1  0  0  1  0  1  0  0  0  0     0  0  0  0  0  1  0  0  0  0  1  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  1  0  1\n",
       " 0  0  0  0  0  0  0  1  0  0  1  0  1     1  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  1  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  1  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  1  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  1  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbatch[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with a 784 inputs layer, followed by a 10 outputs layer with the identity as the activation function, followed by a softmax layer to arrive at the probabilities (softmax ensures that the sum of the outputs from it total to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 10), softmax)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(n_inputs, n_outputs, identity), softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are working with probabilities, we will use crossentropy as the loss function (this kind of informs the model that the expected values are in the range of 0 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x,y) = Flux.crossentropy(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ADAM as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model few times and observe improving loss value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model few times and observe the loss improving. The loss value gives us an understanding on how well the model is doing on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.379892 seconds (20.30 M allocations: 406.186 MiB, 3.57% gc time)\n",
      "  0.970641 seconds (19.75 M allocations: 379.569 MiB, 6.84% gc time)\n"
     ]
    }
   ],
   "source": [
    "# why do we need to put the trainbatch inside [] and not use as is ?\n",
    "@time Flux.train!(loss, params(model), [trainbatch], opt)\n",
    "@time Flux.train!(loss, params(model), [trainbatch], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.299392f0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(trainbatch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.998636 seconds (19.75 M allocations: 379.569 MiB, 6.97% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), [trainbatch], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2460005f0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(trainbatch...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train multiple times, we will use the Iterators.repeated. This does not copy the data multiple times (does not waste memory space), rather it creates an object which loops over the same data multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}}(Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}(([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 0 0 … 0 0])), 100)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iterators.repeated(trainbatch,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Loss automatically using callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we checked the loss value manually after each train cycle. We will use the callback function supported by flux to call a specific function we would want to run after every train step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "callback (generic function with 1 method)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the function we want Flux to call\n",
    "callback() = @show (loss(trainbatch...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(trainbatch...) = 2.1945474f0\n",
      "loss(trainbatch...) = 2.1448946f0\n",
      "loss(trainbatch...) = 2.0969093f0\n",
      "loss(trainbatch...) = 2.050464f0\n",
      "  3.911752 seconds (79.36 M allocations: 1.562 GiB, 6.24% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), Iterators.repeated(trainbatch,4), opt; cb = callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would generally train the model for much higher number of times... and we would not want the loss value to be seen at every train step plus it is computationally intensive too to do at every train step. We can make us of the throttle function that would define the number of seconds to wait between calling two successive callback calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(trainbatch...) = 2.0054407f0\n",
      "loss(trainbatch...) = 1.5202025f0\n",
      "loss(trainbatch...) = 1.1933346f0\n",
      "loss(trainbatch...) = 0.98272187f0\n",
      " 37.204003 seconds (790.38 M allocations: 14.906 GiB, 6.74% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), Iterators.repeated(trainbatch,40), opt; cb = Flux.throttle(callback,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check train and test loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data is the data that the model sees when it is getting trained. Test data is the data that the model does not see - it is the data that is used to test how good the current trained model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 1 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use the next 5000 instances for the test data\n",
    "testbatch = create_batch(5001:10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a custom function that will show the train and test loss as the model is getting trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98272187f0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(trainbatch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_loss! (generic function with 1 method)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = Float64[]\n",
    "test_loss = Float64[]\n",
    "# bang ! denotes you are updating the current data structure\n",
    "function update_loss!()\n",
    "    push!(train_loss, loss(trainbatch...))\n",
    "    push!(test_loss, loss(testbatch...))\n",
    "    # using \"end\" to print the latest loss value that was pushed in\n",
    "    @printf(\"train loss = %.2f, test loss = %.2f \\n\", train_loss[end], test_loss[end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.97, test loss = 1.00 \n",
      "train loss = 0.56, test loss = 0.61 \n",
      "train loss = 0.43, test loss = 0.50 \n",
      "train loss = 0.37, test loss = 0.44 \n",
      "train loss = 0.32, test loss = 0.41 \n",
      "train loss = 0.29, test loss = 0.39 \n",
      "train loss = 0.27, test loss = 0.38 \n",
      "train loss = 0.25, test loss = 0.37 \n",
      "train loss = 0.23, test loss = 0.36 \n",
      "train loss = 0.22, test loss = 0.36 \n",
      "train loss = 0.21, test loss = 0.36 \n",
      "train loss = 0.20, test loss = 0.35 \n",
      "train loss = 0.19, test loss = 0.35 \n",
      "train loss = 0.18, test loss = 0.35 \n",
      "864.882100 seconds (19.75 G allocations: 371.125 GiB, 7.13% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), Iterators.repeated(trainbatch,1000), opt; cb = Flux.throttle(update_loss!,60)) |>gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice following:\n",
    "- loss values improve as the training progresses\n",
    "- test loss > train loss (as the test data is new data for model which it has not seen) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the train and test loss graphs. Notice the following:\n",
    "- both the losses reduce as the number of seconds (training) increase. \n",
    "- there is a gap in the in the train and test loss towards the end - need to further investigate ways to reduce this gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip6200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip6200)\" d=\"\n",
       "M215.754 1425.62 L2352.76 1425.62 L2352.76 47.2441 L215.754 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6202\">\n",
       "    <rect x=\"215\" y=\"47\" width=\"2138\" height=\"1379\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  508.855,1425.62 508.855,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  896.555,1425.62 896.555,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1284.25,1425.62 1284.25,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1671.95,1425.62 1671.95,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2059.65,1425.62 2059.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,1349.08 2352.76,1349.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,1033.57 2352.76,1033.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,718.065 2352.76,718.065 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,402.558 2352.76,402.558 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,87.0519 2352.76,87.0519 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1425.62 215.754,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  508.855,1425.62 508.855,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  896.555,1425.62 896.555,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1284.25,1425.62 1284.25,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1671.95,1425.62 1671.95,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2059.65,1425.62 2059.65,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1349.08 241.398,1349.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1033.57 241.398,1033.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,718.065 241.398,718.065 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,402.558 241.398,402.558 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,87.0519 241.398,87.0519 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 508.855, 1479.62)\" x=\"508.855\" y=\"1479.62\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 896.555, 1479.62)\" x=\"896.555\" y=\"1479.62\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1284.25, 1479.62)\" x=\"1284.25\" y=\"1479.62\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1671.95, 1479.62)\" x=\"1671.95\" y=\"1479.62\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2059.65, 1479.62)\" x=\"2059.65\" y=\"1479.62\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 1366.58)\" x=\"191.754\" y=\"1366.58\">0.2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 1051.07)\" x=\"191.754\" y=\"1051.07\">0.4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 735.565)\" x=\"191.754\" y=\"735.565\">0.6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 420.058)\" x=\"191.754\" y=\"420.058\">0.8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 104.552)\" x=\"191.754\" y=\"104.552\">1.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1284.25, 1559.48)\" x=\"1284.25\" y=\"1559.48\">seconds of training</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 736.431)\" x=\"89.2861\" y=\"736.431\">loss</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.235,134.417 431.315,774.814 586.395,979.716 741.475,1085.86 896.555,1154.02 1051.64,1202.61 1206.72,1240.35 1361.79,1271.45 1516.87,1297.51 1671.95,1320.16 \n",
       "  1827.03,1339.65 1982.11,1356.7 2137.19,1372.41 2292.27,1386.61 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6202)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.235,86.2547 431.315,697.845 586.395,880.173 741.475,965.689 896.555,1014.48 1051.64,1044.97 1206.72,1065.49 1361.79,1079.92 1516.87,1090.02 1671.95,1097.16 \n",
       "  1827.03,1101.95 1982.11,1104.99 2137.19,1106.76 2292.27,1107.41 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip6200)\" d=\"\n",
       "M1947.14 312.204 L2280.76 312.204 L2280.76 130.764 L1947.14 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1947.14,312.204 2280.76,312.204 2280.76,130.764 1947.14,130.764 1947.14,312.204 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1971.14,191.244 2115.14,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2139.14, 208.744)\" x=\"2139.14\" y=\"208.744\">train</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6200)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1971.14,251.724 2115.14,251.724 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2139.14, 269.224)\" x=\"2139.14\" y=\"269.224\">test</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(1:length(train_loss), train_loss, label = \"train\")\n",
    "plot!(1:length(test_loss), test_loss, label = \"test\")\n",
    "plot!(xlabel = \"seconds of training\", ylabel = \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the prediction for couple of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5001 image - labelled as 7, model detects as 7 with highest probability. The next highest probability is for digit 2. Notice, if there is a loop at the bottom, the 7 will look like a 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHmSURBVGje7dm9axRBHMbxj0YFu1QGQTCoUQMWAQut1T9B8AURRES0EQvLdJZGFMHSVrCMVioEVBQLQWJhrUVEfD1PlBQhFjMkF8lebm/BG4d5mpld7n5fnnvutzO7S1FRUVFRUVFRUVFRUXOtq/PhM1jEF4zjBZ7WBK7/1w7zB67I8CQmhKxW03AcF7AJv/ELb3AMn1J0mD9wKcNruIShPgvNCP+Bj6k5zB+4lOF7bMOs0F+deobpVb58GKcxGo9ncFz3fsz/Jx1chruxD4/QrlFgB+4L6yNcwVRKDvMH1trTVOko7sX5Z2xJyWEBFmD6wA1NC1zE/o7jzfH4VSoO8wfWupZuxSlh/9p57u8iPyzfhwzcYf7AnvrwiNBb54Q9zFq6k5LD/IFdMxzDbRyystfe4VucT2Iet7AnnvuQksP8gZUZXhbWup34iRZuYA7PhRw71YpjGw9Scpg/sDLDg0J+07iOJ12KTGB7nM/jbUoO8wdWZnhBeA56tYciuzAS549Tc5g/sDLDr3rLDw7E8buwLiblMH9g4/vDWeyN84fC+6ikHOYPbJzhaCzSws0UHeYPbJThCeG5TBvnrd2DA3GYP7DvZ94b8VK4jt7F2VQd5g/suw8XhexeC++rknWYP7Do/9cfyWhEoqqYtCQAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7, (0.82491916f0, 7))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5001\n",
    "display(images[i])\n",
    "# findmax returns the max value of the iteration followed by the index\n",
    "# you can get the max value and index of max value separately using [1] and [2] after the expression\n",
    "# here the index value of 1 corresponds to digit 0 ... index value of 10 corresponds to 9\n",
    "# hence, we need to subtract 1 from the returned index value to get the predicted digit\n",
    "# as the expression returns both max value and index of max value... subtraction needs to be done on both\n",
    "# hence, we broadcast (.) subtraction over both... where in the max value is subtracted by 0, index by 1, hence .-(0,1)\n",
    "labels[i], findmax(model(preprocess(images[i]))) .- (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 1.47012215e-5 \n",
       " 1.3659076e-5  \n",
       " 0.15183854    \n",
       " 0.01979705    \n",
       " 0.000104114784\n",
       " 2.3618115e-6  \n",
       " 1.1035284e-5  \n",
       " 0.82491916    \n",
       " 0.0013060396  \n",
       " 0.0019933602  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preprocess(images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5002 image - labelled as 3, model detects as 3 with the highest probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIkSURBVGje7dm9j0xRGAbwH9luSzOJyurY6ITSREV0VumjJFEJlY/QYFUSqyH+AI3NlrRkK4TtLC0do9YZxXs2Mzsz695Zyc51cp5kcjP3nnOfec4z73vOew4FBQUFBQUFBf8/dm2n0xwu4iZ66SXruI2Vir67d1ph/oQTedjGDZzDntS5N3D9hqPoNklh/oS1PbyFu0Y9+5Get7Afn3CoSQrzJ6zt4Xsctjl3HtePuWN4nZ7PNElh/oS1PJzHO/wUcdfFNVzBIr6mdj38xmU8a4rC/Alrx+FB4d1G3F3CEzH/fcQZvBA+7rX1nJj/kO444Uzdhp+HvnfxRcTmVVwXf4hBnxuhMH/C2h5CRz8e13EAb8V6tSfy7KmmKcyfcCIPz4q6cLCmaOvH32ORVxulMH/CiTwkvBu+roo1TpV/U1GYP+FEHj4XezQtkVNn0/076vk3FYX5E25rr43w8B5OY03Mg90a/fIf0uZ42Nbfg/kbXuGkyKWPmqgwf8KxubSDh6KeuFDxgkWcEGvURirMn3DEwzae4rtq/2ZT20kScv5DOn0PF0RMvanoOI/l1LZndA+gMQrzJxzxcDX9ig7Oi1r+Q3o2J/a2F8RaZqNOXEqfRirMn3BsGly22aO1dH+f0XPD+6K2r7MmnYrC/AnHetjGSxwR5xDDZ72/RHw+UH1uP3WF+RNuuRxpiTNf4oxiRT/WltSf/6auMH/CgoKCgoJ/xx/1U2OI38wMJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3, (0.9965526f0, 3))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5002\n",
    "display(images[i])\n",
    "labels[i], findmax(model(preprocess(images[i]))) .- (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 1.0651071e-5 \n",
       " 7.117327e-7  \n",
       " 5.5700795e-5 \n",
       " 0.9965526    \n",
       " 2.8131538e-8 \n",
       " 4.370113e-5  \n",
       " 4.869005e-9  \n",
       " 6.533285e-6  \n",
       " 0.002962886  \n",
       " 0.00036723318"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preprocess(images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5003 image - labelled as 4, model detects as 9 with a highest probability. Observe, next highest probability is for 4. Notice, if there is a small loop at the top, the 4 in the image will become a 9 - this is what the model got confused with and detected the 4 incorretly as 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHNSURBVGje7dm9axVBFMbhxw8iaeIHgoWQJpBGsBBMI0QFa/8BG61SCYI2glioiIhFULARU1sIWokgERsLQRACgRQWQkRIIxYKITFiMXPxIqu73gve4TBvM2fhLL99edndM7tUVVVVVVVVVVVVjV7bujaOYRHH8klfcBir/wjc/r8dxgfu7NI0hodSfvAUt/CpofcA1kpyGB/YKcOLOJPr+7iE9Ya+OziH65gvxWF8YGuGh3Al119xAd8b+o7iLPaW5jA+sDXDyxiXcjutOT/SvbkPm9KzthiH8YGtGR7J63O8yvUO6R3Z0xSO5/oxPpTkMD6w0/sQduV1BjdwqqFnDTdLcxgf2JrhbSzgJF5i9i9X+QDLpTmMD2zNcLKv8USu3+AJDuJ8X+/bEh3GB7ZmuICNvuNH0r5+S5p3enqNZyU6jA9szfCjtJ9v0re++q4/z6wjdRgf2HmmadJWXn/gfakO4wOHynAury/wrlSH8YEDZ7gbE7meL9lhfODAGc5IM+smPpfsMD6w87+n37WCaSm//SU7jA8c+D7sfbdZKt1hfOBQMw2/ZtNiHcYHDp3hLK7iWqkO4wMHzvCe9F9xj7Q/LNZhfGBVVdXo9RMOrDs1WxoKXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4, (0.86017096f0, 9))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5003\n",
    "display(images[i])\n",
    "labels[i], findmax(model(preprocess(images[i]))) .- (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 3.0339202e-6\n",
       " 2.8136736e-7\n",
       " 5.317315e-7 \n",
       " 0.0026459738\n",
       " 0.08925709  \n",
       " 0.0101921335\n",
       " 3.6720678e-5\n",
       " 0.0058719506\n",
       " 0.031821303 \n",
       " 0.86017096  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preprocess(images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy of prediction i.e. how much percentae of images(digits) got predicted correctly. We will do this both train and test images to get train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction custom function returns the predicted digit\n",
    "# for the findmax we need to subtract 1 from the returned index at [2] location to get the predicted digit\n",
    "prediction(i) = findmax(model(preprocess(images[i])))[2] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_correct (generic function with 2 methods)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expression returns 1 if prediction and ground truth labels are equal or 0\n",
    "# sum of above ... divided by total number of instance ... gives the how many instances got predicted accurately\n",
    "prediction_correct(r,n) = ((sum(labels[i] == prediction(i) for i in r)) / n) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.36"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = prediction_correct(1:5000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.88000000000001"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = prediction_correct(5001:10000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update Model and improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 20 hidden neurons to the model to handle more complexity. Use relu (zero for <0; identity for >=0) as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 20, relu), Dense(20, 10), softmax)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 20\n",
    "model = Chain(Dense(n_inputs, n_hidden, relu),\n",
    "              Dense(n_hidden, n_outputs, identity),\n",
    "              softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the arrays holding the loss values to populate with new data from the updated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Float64,1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the train and test loss arrays to populate it with data from the updated model\n",
    "train_loss = Float64[]\n",
    "test_loss = Float64[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 2.29, test loss = 2.29 \n",
      "train loss = 0.57, test loss = 0.62 \n",
      "train loss = 0.33, test loss = 0.41 \n",
      "train loss = 0.24, test loss = 0.36 \n",
      "train loss = 0.18, test loss = 0.33 \n",
      "train loss = 0.15, test loss = 0.32 \n",
      "train loss = 0.12, test loss = 0.32 \n",
      "train loss = 0.10, test loss = 0.32 \n",
      "train loss = 0.08, test loss = 0.32 \n",
      "train loss = 0.07, test loss = 0.33 \n",
      "train loss = 0.05, test loss = 0.33 \n",
      "train loss = 0.04, test loss = 0.34 \n",
      "train loss = 0.04, test loss = 0.35 \n",
      "train loss = 0.03, test loss = 0.36 \n",
      "train loss = 0.03, test loss = 0.36 \n",
      "896.142363 seconds (19.75 G allocations: 373.119 GiB, 7.19% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, params(model), Iterators.repeated(trainbatch,1000), opt; cb = Flux.throttle(update_loss!, 60)) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip6600)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6601\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip6600)\" d=\"\n",
       "M215.754 1425.62 L2352.76 1425.62 L2352.76 47.2441 L215.754 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6602\">\n",
       "    <rect x=\"215\" y=\"47\" width=\"2138\" height=\"1379\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  420.238,1425.62 420.238,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  708.244,1425.62 708.244,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  996.249,1425.62 996.249,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1284.25,1425.62 1284.25,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1572.26,1425.62 1572.26,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1860.27,1425.62 1860.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2148.27,1425.62 2148.27,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,1402.47 2352.76,1402.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,1114.97 2352.76,1114.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,827.466 2352.76,827.466 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,539.965 2352.76,539.965 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  215.754,252.464 2352.76,252.464 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1425.62 215.754,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  420.238,1425.62 420.238,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  708.244,1425.62 708.244,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  996.249,1425.62 996.249,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1284.25,1425.62 1284.25,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1572.26,1425.62 1572.26,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1860.27,1425.62 1860.27,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2148.27,1425.62 2148.27,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1402.47 241.398,1402.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,1114.97 241.398,1114.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,827.466 241.398,827.466 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,539.965 241.398,539.965 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.754,252.464 241.398,252.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 420.238, 1479.62)\" x=\"420.238\" y=\"1479.62\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 708.244, 1479.62)\" x=\"708.244\" y=\"1479.62\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 996.249, 1479.62)\" x=\"996.249\" y=\"1479.62\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1284.25, 1479.62)\" x=\"1284.25\" y=\"1479.62\">8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1572.26, 1479.62)\" x=\"1572.26\" y=\"1479.62\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1860.27, 1479.62)\" x=\"1860.27\" y=\"1479.62\">12</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2148.27, 1479.62)\" x=\"2148.27\" y=\"1479.62\">14</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 1419.97)\" x=\"191.754\" y=\"1419.97\">0.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 1132.47)\" x=\"191.754\" y=\"1132.47\">0.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 844.966)\" x=\"191.754\" y=\"844.966\">1.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 557.465)\" x=\"191.754\" y=\"557.465\">1.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 191.754, 269.964)\" x=\"191.754\" y=\"269.964\">2.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1284.25, 1559.48)\" x=\"1284.25\" y=\"1559.48\">seconds of training</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 736.431)\" x=\"89.2861\" y=\"736.431\">loss</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.235,87.0136 420.238,1075.55 564.241,1215.51 708.244,1265.99 852.247,1296.77 996.249,1318.08 1140.25,1334.06 1284.25,1346.8 1428.26,1356.79 1572.26,1364.97 \n",
       "  1716.26,1371.62 1860.27,1376.89 2004.27,1381.08 2148.27,1384.17 2292.27,1386.61 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6602)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.235,86.2547 420.238,1043.47 564.241,1164.08 708.244,1197.35 852.247,1212.03 996.249,1218.73 1140.25,1221.1 1284.25,1220.93 1428.26,1219.04 1572.26,1215.58 \n",
       "  1716.26,1211.19 1860.27,1206.64 2004.27,1202.08 2148.27,1197.97 2292.27,1193.95 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip6600)\" d=\"\n",
       "M1947.14 312.204 L2280.76 312.204 L2280.76 130.764 L1947.14 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1947.14,312.204 2280.76,312.204 2280.76,130.764 1947.14,130.764 1947.14,312.204 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1971.14,191.244 2115.14,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2139.14, 208.744)\" x=\"2139.14\" y=\"208.744\">train</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6600)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1971.14,251.724 2115.14,251.724 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2139.14, 269.224)\" x=\"2139.14\" y=\"269.224\">test</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(1:length(train_loss), train_loss, label = \"train\")\n",
    "plot!(1:length(test_loss), test_loss, label = \"test\")\n",
    "plot!(xlabel = \"seconds of training\", ylabel = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.83999999999999"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = prediction_correct(1:5000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.72"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = prediction_correct(5001:10000,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the train loss is quite small towards the end. However, the test loss increases after certain point (you can see that in the loss values as well as in the plots).\n",
    "\n",
    "**Updated Model - Total number of parameters = 15910**\n",
    "- 784 inputs * 20 hidden neuron = 15680 weights\n",
    "- 20 biases for the 20 hidden neurons\n",
    "- 20 hidden neuron * 10 outputs = 200 weights\n",
    "- 10 biases for the 10 outputs\n",
    "- 15680 + 20 + 200 + 10 = 15910\n",
    "\n",
    "**Initial Model - Total number of parameters = 7850**\n",
    "- 784 inputs * 10 outputs = 7840 weights\n",
    "- 10 biases for the 10 outputs\n",
    "- 7840 + 10 = 7850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "1. You can notice that the test loss is increasing after we added more complexity (more parameters) to the model i.e. it is overfitting  => We need to reduce the number of parameters or train with more samples.\n",
    "2. Our input is a 28x28 image, however, we are feeding it to the model as a vector which loses the spatial information of the one pixel to the other. And we did so because the the model topology (multi-layer perceptron) expects the input in a vetor form. Also we used the Dense function which connects every input to every output as needed for a multi-layer perceptron which probably could be adding more complexity than needed. We can alternatively go for a model topology which retains the image structure as a matrix for processing and connects few inputs to few outputs i.e. a Convolution Neural Network (CNN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
